\documentclass[12pt, 
	a4paper, 
	%landscape, 
	oneside, 
	leqno]{scrreprt}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage[left=2cm, right=2cm, top=2.5cm, bottom=3.5cm]{geometry}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath, cancel}
\usepackage{thmtools}
\usepackage{url}


\begin{document}

\begin{titlepage}
\begin{center}

\begin{Huge}
\textbf{   Grundlagenkurs Data Science}
\newline\newline
\end{Huge}

\begin{LARGE}
Forschungstagebuch \\
<<Data Science Project>> \\
\end{LARGE}
\vfill
\textbf{Working Title: Broccoli}

\end{center}
\vfill
Laura Hartgers s0556238 \\
Adrian Saiz s0554249 \\
Christoph Stach s0555912 \\
\\
betreut durch Prof. Dr. Christin Schmidt \\
Hochschule für Technik und Wirtschaft Berlin
\end{titlepage}

\setcounter{tocdepth}{2} %Tiefe des Inhaltsverzeichnis
\tableofcontents
\pagebreak

\chapter{Problemformulierung}

Dieses Projekt umfasst eine explorative / hypothesensuchende Studie nach dem Inhalt von Twitter.
\\
Die von Twitter bereitgestellte API bietet die Mögichkeit zu suchen auf followings, locations und trackTerms.
\\
Das Team interessiert sich momentan für politische Themen, sowie die AfD, NPD, Trump und radikalisierung. 
\\
Das Team hat sich entschieden auf eine noch festzulegende Schlagwörterliste zu filtern, und dabei sowohl auf followings als die trackTerms zu filtern. Erzielt wird das eheben der Tweets aller User die im Zeitbereich der Datenerhebung über die ausgewählte Themen twittern als die Tweets der User die bestimmte Twitterprofile folgen.

%Darstellung der empirischen Untersuchbarkeit / Angemessenheit 
%des Arbeitsaufwandes 
%Hinweis:  
%Vorläufige Untersuchungsideen sind unbrauchbar, ... 
%... wenn unklar bleibt, was der eigentliche Gegenstand der 
%Untersuchung sein soll, oder 
%...der Gegenstand, auf den sich die Untersuchung bezieht, so 
%vielschichtig ist, dass sich aus ihm viele unterschiedliche 
%Fragestellungen ableiten lassen. 


\subparagraph{Teilfragen}

ggf. Teilfragen entwickeln und zunächst diese beantworten \\

Sentiment analyse???

\chapter{Theorie}

Literaturstudium (Stand der Wissenschaft) \\

Explorativ/ Hypothesensuchend: Was gibt es schon? \\

Erkundung (Warum dieses Thema? Lücke in Wissenschaft?, 
eigenes Interesse?, Zufall?, .... ) \\
- Eigenes Interesse in ausprobieren von Methoden die im Data Science Bereich benutzt werden. \\
-Interessant weil kombinierbar mit aktuelle Programmierkenntnisse.

\chapter{Methodologie / Untersuchungsplanung}

%Wie gehen sie vor und warum? Welche Werkzeuge nutzen Sie? 

%Datenbeschaffung (Qualität und Quantität der Daten mit 
%Darstellung weiterer Quellen / Erhebungsmethoden?) 
%Erhebungsart  
%Stichprobe 
%Auswertungsmethoden 

%Ethische Kriterien berücksichtigen (vgl. Data Privacy) 
%Missbrauch personenbezogener Daten (Anonymisierung, 
%Pseudonymisierung)  

%Beeinträchtigung der Untersuchungsteilnehmer

\chapter{Herausforderungen}

\chapter{Untersuchungsdurchführung}

\chapter{Ergebnisse}

\chapter{Quellen}

\chapter{Team Working Agreements}

1. Jede Woche Montag 15.30 ist Teammeeting.\\
\\
2. Verantwortungsvoll mit dem Server umgehen und jeder dokumentiert selbst was er darauf macht. \\
\\
3. Aufgaben werden etwa gleichmäßig über das Team verteilt. Stärken und Schwächen werden dabei berücksichtigt. Jeder hat Vertantwortung für seine eigene Aufgaben. Teammitglieder sprechen ein Teammitglied, das seine Aufgabe nicht in der abgesprochene Zeit erledigt hat, spätenstens einen Tag später darauf an.\\
\\
4. Projektstrukturierung / Aufgabenverteilung mit Trello. 

\chapter{Diskussion}

\chapter{Tagebücher}

\section{Christoph Stach}

Ich fasse hier mal zusammen was ich bisher so gemacht habe.
Damit können wir uns später besser einen Überblick verschaffen und gegebenfalls eine Timeline erstellen.

\subsection*{Recherche}


\begin{itemize}
  \item \textbf{27.04.2017:} Wo bekommen wir die Daten her?
  \item \textbf{27.04.2017:} Twitter Streaming API streamt Tweets sobald Sie getweeted werden zu einem Client
  \item \textbf{27.04.2017:} Entscheidung: Hosebird Client (hbc), weil offiziell von Twitter entwickelt
  \item \textbf{08.04.2017:} Wie kann man Text analysieren? Ggf. NLP Techniken anwenden
  \item \textbf{11.04.2017:} Testen der NLP Library http://www.spacy.io/
  \item \textbf{11.04.2017:} Erfolreiche Extrahierung von \textit{Named Entities} mit SpaCy aus Tweets
  \item \textbf{14.05.2017:} Interessante Studie, die ähnlich unserer ist: http://www.ling.uni-potsdam.de/~scheffler/twitter/
  \item \textbf{15.05.2017:} Consumer sind jetzt per config.yml aktivierbar  
\end{itemize}



\subsection*{DataMiner}

\begin{itemize}
  \item \textbf{27.04.2017:} Erste Erstellung eines lauffähigen Prototypens welcher sich auf die Twitter Streaming API verbindet und Tweets empfängt
  \item \textbf{08.05.2017:} Consumer können sich jetzt auf mit dem Twitter Client verbinden und auf auftretende Tweets reagieren
  \item \textbf{08.05.2017:} Implementierung eines MongoDB Consumers, mit MongoDB lassen sich einfach JSON Objekte speichern und bei bedarf durchsuchen. Die Twitter API sendet Tweets im JSON Format, von daher erweist sich MongoDB als idealer initialer Datenspeicher.
  \item \textbf{14.05.2017:} Implementierung für den Locationfilter
  \item \textbf{14.05.2017:} Erstellung eines Shellscripts um den Twitter Client auf dem Server im Hintergrund laufen zu lassen
  \item \textbf{16.05.2017:} Verbesserung des Twitter Clients und Unterschützung für mehrfache Locationfilter
\end{itemize}

\subsection*{Server}

\begin{itemize}
  \item \textbf{14.05.2017:} Upload des Twitter Clients auf den Server um einen Testlauf zu starten (Tweets in Berlin)
\end{itemize}

\end{document}
